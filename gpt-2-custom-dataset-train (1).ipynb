{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-19T17:54:42.803556Z","iopub.execute_input":"2021-12-19T17:54:42.803896Z","iopub.status.idle":"2021-12-19T17:54:42.817587Z","shell.execute_reply.started":"2021-12-19T17:54:42.803844Z","shell.execute_reply":"2021-12-19T17:54:42.816699Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pip install git+https://github.com/huggingface/transformers@master","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:54:42.819138Z","iopub.execute_input":"2021-12-19T17:54:42.819512Z","iopub.status.idle":"2021-12-19T17:55:13.286348Z","shell.execute_reply.started":"2021-12-19T17:54:42.819479Z","shell.execute_reply":"2021-12-19T17:55:13.285603Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, random_split\nfrom transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:55:13.288169Z","iopub.execute_input":"2021-12-19T17:55:13.288457Z","iopub.status.idle":"2021-12-19T17:55:20.451058Z","shell.execute_reply.started":"2021-12-19T17:55:13.288413Z","shell.execute_reply":"2021-12-19T17:55:20.450331Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:55:20.453132Z","iopub.execute_input":"2021-12-19T17:55:20.453378Z","iopub.status.idle":"2021-12-19T17:55:21.303343Z","shell.execute_reply.started":"2021-12-19T17:55:20.453334Z","shell.execute_reply":"2021-12-19T17:55:21.302542Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:55:21.307871Z","iopub.execute_input":"2021-12-19T17:55:21.308148Z","iopub.status.idle":"2021-12-19T17:55:21.324694Z","shell.execute_reply.started":"2021-12-19T17:55:21.308111Z","shell.execute_reply":"2021-12-19T17:55:21.324099Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium', bos_token='<|startoftext|>',\n                                          eos_token='<|endoftext|>', pad_token='<|pad|>')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2-medium').cuda()\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:55:21.328289Z","iopub.execute_input":"2021-12-19T17:55:21.330130Z","iopub.status.idle":"2021-12-19T17:56:13.493715Z","shell.execute_reply.started":"2021-12-19T17:55:21.330094Z","shell.execute_reply":"2021-12-19T17:56:13.492860Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"descriptions = pd.read_csv('../input/netflix-shows/netflix_titles.csv')['description']\ndescriptions","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:56:13.495142Z","iopub.execute_input":"2021-12-19T17:56:13.495475Z","iopub.status.idle":"2021-12-19T17:56:13.656545Z","shell.execute_reply.started":"2021-12-19T17:56:13.495436Z","shell.execute_reply":"2021-12-19T17:56:13.655867Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"max_length = max([len(tokenizer.encode(description)) for description in descriptions])","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:56:13.657811Z","iopub.execute_input":"2021-12-19T17:56:13.658080Z","iopub.status.idle":"2021-12-19T17:56:17.552545Z","shell.execute_reply.started":"2021-12-19T17:56:13.658044Z","shell.execute_reply":"2021-12-19T17:56:17.551800Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class NetflixDataset(Dataset):\n    def __init__(self,txt_list, tokenizer,max_length):\n        self.input_ids = []\n        self.attn_mask = []\n        self.labels = []\n        for txt in txt_list:\n            encodings_dict = tokenizer('<|startoftext|>' + txt + '<|endoftext|>', truncation =True, max_length = max_length, padding = \"max_length\")\n            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n            self.attn_mask.append(torch.tensor(encodings_dict['attention_mask']))\n            \n    def __len__(self):\n        return len(self.input_ids)\n    \n    def __getitem__(self, idx):\n        return self.input_ids[idx],self.attn_mask[idx]\n        ","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:56:17.553851Z","iopub.execute_input":"2021-12-19T17:56:17.554123Z","iopub.status.idle":"2021-12-19T17:56:17.561394Z","shell.execute_reply.started":"2021-12-19T17:56:17.554088Z","shell.execute_reply":"2021-12-19T17:56:17.560650Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset = NetflixDataset(descriptions, tokenizer, max_length = max_length)\ntrain_size = int(0.9 * len(dataset))\ntrain_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size ])","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:56:17.564030Z","iopub.execute_input":"2021-12-19T17:56:17.564844Z","iopub.status.idle":"2021-12-19T17:56:21.264867Z","shell.execute_reply.started":"2021-12-19T17:56:17.564805Z","shell.execute_reply":"2021-12-19T17:56:21.264121Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:56:21.266153Z","iopub.execute_input":"2021-12-19T17:56:21.266416Z","iopub.status.idle":"2021-12-19T17:56:21.489809Z","shell.execute_reply.started":"2021-12-19T17:56:21.266383Z","shell.execute_reply":"2021-12-19T17:56:21.489132Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:56:21.491269Z","iopub.execute_input":"2021-12-19T17:56:21.491785Z","iopub.status.idle":"2021-12-19T17:56:21.497877Z","shell.execute_reply.started":"2021-12-19T17:56:21.491746Z","shell.execute_reply":"2021-12-19T17:56:21.497198Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(output_dir = \"./results\", num_train_epochs=1, logging_steps = 100, save_steps=5000,\n                                  per_device_train_batch_size=1, per_device_eval_batch_size=1,\n                                  warmup_steps=10, weight_decay=0.05, logging_dir='./logs', report_to = 'none')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:56:51.195008Z","iopub.execute_input":"2021-12-19T17:56:51.195864Z","iopub.status.idle":"2021-12-19T17:56:51.201392Z","shell.execute_reply.started":"2021-12-19T17:56:51.195816Z","shell.execute_reply":"2021-12-19T17:56:51.200594Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"Trainer(model=model,  args=training_args, train_dataset=train_dataset, \n        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n                                                              'attention_mask': torch.stack([f[1] for f in data]),\n                                                              'labels': torch.stack([f[0] for f in data])}).train()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T17:56:53.248877Z","iopub.execute_input":"2021-12-19T17:56:53.249321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GPT Generated Description","metadata":{}},{"cell_type":"code","source":"generated = tokenizer(\"<|startoftext|> \", return_tensors=\"pt\").input_ids.cuda()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_outputs = model.generate(generated, do_sample=True, top_k=50, \n                                max_length=300, top_p=0.95, temperature=1.9, num_return_sequences=20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, sample_output in enumerate(sample_outputs):\n    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_colwidth = 1000\ndescriptions.sample(10)","metadata":{},"execution_count":null,"outputs":[]}]}